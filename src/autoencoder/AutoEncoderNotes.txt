Un AutoEncoder est un type de réseau de neurones utilisé pour apprendre des représentations efficaces des données,
 typiquement pour les tâches de réduction de dimension ou de compression. Il se compose de deux parties :

Encoder : réduit les dimensions des données d'entrée à un espace latent de plus petite taille.
Decoder : reconstruit les données originales à partir de l'espace latent.




model:
    Activation ReLU : Nous utilisons l'activation 'relu' (Rectified Linear Unit) pour la majorité des couches cachées de
    l'AutoEncoder. La fonction 'relu' est couramment utilisée dans les réseaux de neurones car elle aide à résoudre le problème
    du gradient évanescent, permettant ainsi un apprentissage plus efficace dans les réseaux profonds. Elle est également rapide
    à calculer et introduit de la non-linéarité, ce qui permet au modèle d'apprendre des relations complexes dans les données.

    Dimension des couches : Les dimensions des couches intermédiaires (128, 64) sont choisies pour graduellement réduire la
    dimensionnalité des données avant de les encoder dans l'espace latent. Cette réduction progressive permet de capturer
    les caractéristiques essentielles des données tout en minimisant la perte d'information.

    Activation Sigmoid pour la sortie : Nous utilisons l'activation 'sigmoid' pour la couche de sortie afin de contraindre
    les valeurs de sortie à l'intervalle [0, 1]. Ceci est particulièrement approprié pour les données d'image MNIST, où les
    pixels sont normalisés entre 0 et 1. L'activation 'sigmoid' est idéale pour ce type de tâche car elle permet de modéliser
    les probabilités des pixels de l'image reconstruite.

    Perte Binary Crossentropy : La fonction de perte 'binary_crossentropy' est utilisée car elle est bien adaptée aux tâches
    de reconstruction d'images binaires ou normalisées dans [0, 1]. Elle mesure la différence entre les distributions de
    probabilité des pixels des images d'entrée et reconstruites, favorisant des reconstructions plus précises.
